{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS5jhdJbp98C"
   },
   "source": [
    "# LDA2Vec\n",
    "Adapted from tensorflow implementation: \n",
    "\n",
    "(Current) https://github.com/nateraw/Lda2vec-Tensorflow\n",
    "\n",
    "(Old) https://github.com/meereeum/lda2vec-tf\n",
    "\n",
    "(Original) https://github.com/cemoody/lda2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1HBXFOPqJOj",
    "outputId": "6ee5f2d9-9b99-4dfc-f470-d11f82c38409"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sfl9g1ze76ZO"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Lda2vec-Tensorflow-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-Apc0J1AqXEb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/keanl/miniforge3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from lda2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0Metal device set to: Apple M1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:26:43.994139: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-20 00:26:43.994227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc9Dtw23LCZW"
   },
   "source": [
    "## Find Ending Index of Documents for Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jLxxcVZILKU8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"papers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2l7eKMuzLQzQ"
   },
   "outputs": [],
   "source": [
    "data = data.sort_values(by=[\"year\"], kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GG82lAG-LTHM"
   },
   "outputs": [],
   "source": [
    "years = list(data[\"year\"].unique())\n",
    "counts = list(data[\"year\"].value_counts())[::-1]\n",
    "for i in range(1,len(counts)):\n",
    "  counts[i] += counts[i-1]\n",
    "year_index = {years[i]:counts[i] for i in range(len(years))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMSZIaUhRHgK",
    "outputId": "c9988150-618a-4e4c-f8b9-aad2953134d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1987: 90,\n",
       " 1988: 184,\n",
       " 1989: 285,\n",
       " 1990: 412,\n",
       " 1991: 552,\n",
       " 1992: 695,\n",
       " 1993: 839,\n",
       " 1994: 989,\n",
       " 1995: 1139,\n",
       " 1996: 1290,\n",
       " 1997: 1442,\n",
       " 1998: 1594,\n",
       " 1999: 1746,\n",
       " 2000: 1904,\n",
       " 2001: 2101,\n",
       " 2002: 2299,\n",
       " 2003: 2503,\n",
       " 2004: 2710,\n",
       " 2005: 2917,\n",
       " 2006: 3124,\n",
       " 2007: 3341,\n",
       " 2008: 3591,\n",
       " 2009: 3853,\n",
       " 2010: 4145,\n",
       " 2011: 4451,\n",
       " 2012: 4811,\n",
       " 2013: 5179,\n",
       " 2014: 5582,\n",
       " 2015: 5993,\n",
       " 2016: 6562,\n",
       " 2017: 7241}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUjvC2BluF1s"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "$\\tt cleaned.txt$ is a txt file with all NIPS papers with all stop words and words with $\\rm{length} \\leq 3$ removed.\n",
    "\n",
    "Preprocess incorporates tokenization (splitting sentences into words), creating a vocabulary to save mappings from tokens to integer indices, and generating skip-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_fTVmdGwuHrv"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned.txt\")\n",
    "df = df[df[\"stop_removed_paper_text\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VkyneGh_RHDq"
   },
   "outputs": [],
   "source": [
    "df = df[4451:4551] # Use only 2011 papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1FFPTwywuXJe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keanl/miniforge3/lib/python3.9/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_sm' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a preprocessor\n",
    "P = nlppipe.Preprocessor(df, \"stop_removed_paper_text\", max_features=30000, maxlen=10000, min_count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeW0xp3dvDyo",
    "outputId": "67e5aeda-9720-445d-e4b9-a927784d1845"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Tokenizing Texts ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:35,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 12703 low frequency tokens out of 14216 total tokens\n",
      "\n",
      "---------- Getting Skipgrams ----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:02, 49.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run the preprocessing on your dataframe\n",
    "P.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keanl/miniforge3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Should we load pretrained embeddings from file\n",
    "load_embeds = True\n",
    "\n",
    "# Load embeddings from file if we choose to do so\n",
    "if load_embeds:\n",
    "    # Load embedding matrix from file path - change path to where you saved them\n",
    "    embedding_matrix = P.load_glove(\"glove.6B.300d.txt\")\n",
    "else:\n",
    "    embedding_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7y2VxT6kvHKH"
   },
   "outputs": [],
   "source": [
    "# Save data to data_dir\n",
    "P.save_data(\"clean_data11\", embedding_matrix=embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzdVCxyOSd-s"
   },
   "source": [
    "## Using the LDA2Vec Model\n",
    "\n",
    "Using the LDA2Vec model on preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0tjWK7FiSgw7"
   },
   "outputs": [],
   "source": [
    "# Path to preprocessed data\n",
    "data_path  = \"clean_data\"\n",
    "# Whether or not to load saved embeddings file\n",
    "load_embeds = True\n",
    "\n",
    "# Load data from files\n",
    "(idx_to_word, word_to_idx, freqs, pivot_ids,\n",
    " target_ids, doc_ids, embed_matrix) = utils.load_preprocessed_data(data_path, load_embed_matrix=load_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-EtoUS_dSj6E"
   },
   "outputs": [],
   "source": [
    "# Number of unique documents\n",
    "num_docs = doc_ids.max() + 1\n",
    "# Number of unique words in vocabulary (int)\n",
    "vocab_size = len(freqs)\n",
    "# Embed layer dimension size\n",
    "# If not loading embeds, change 128 to whatever size you want.\n",
    "embed_size = embed_matrix.shape[1] if load_embeds else 128\n",
    "# Number of topics to cluster into\n",
    "num_topics = 20\n",
    "# Amount of iterations over entire dataset\n",
    "num_epochs = 50\n",
    "# Batch size - Increase/decrease depending on memory usage\n",
    "batch_size = 4096\n",
    "# Epoch that we want to \"switch off\" regularization\n",
    "switch_loss_epoch = 0\n",
    "# Pretrained embeddings value\n",
    "pretrained_embeddings = embed_matrix if load_embeds else None\n",
    "# If True, save logdir, otherwise don't\n",
    "save_graph = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "Qx68KWfkS6sd",
    "outputId": "9a122837-2fac-49a4-ad33-8a5ff67f85c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:26:51.045716: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-20 00:26:51.045773: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-11-20 00:26:51.204577: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-20 00:26:51.204703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "m = model(num_docs,\n",
    "          vocab_size,\n",
    "          num_topics,\n",
    "          embedding_size=embed_size,\n",
    "          pretrained_embeddings=pretrained_embeddings,\n",
    "          freqs=freqs,\n",
    "          batch_size = batch_size,\n",
    "          save_graph_def=save_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uAHda-IRTQvW",
    "outputId": "ef865d92-1c10-4999-c69a-7392dc283926",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:26:51.871949: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:26:51.894388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:26:51.900358: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:27:17.027727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 1577.5953 w2v 14.610157 lda 1562.9852 reg 64.68488\n",
      "\n",
      "EPOCH: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:27:41.709085: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 1324.7041 w2v 21.55562 lda 1303.1484 reg 64.992744\n",
      "\n",
      "EPOCH: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:28:06.533382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 1087.3585 w2v 4.640275 lda 1082.7183 reg 65.40616\n",
      "\n",
      "EPOCH: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:28:30.810571: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 910.36816 w2v 4.997916 lda 905.37024 reg 66.42735\n",
      "\n",
      "EPOCH: 5\n",
      "LOSS 773.0089 w2v 4.5691667 lda 768.43976 reg 68.28467\n",
      "WARNING:tensorflow:From /Users/keanl/miniforge3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:28:55.084189: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:28:55.102690: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Closest 10 words to given indexes----------\n",
      "Topic 0 : lastly, interestingly, likewise, aforementioned, additionally, furthermore, etc, conversely, resultant, implying\n",
      "Topic 1 : lastly, interestingly, likewise, conversely, importantly, fortunately, furthermore, aforementioned, langford, additionally\n",
      "Topic 2 : lastly, interestingly, likewise, aforementioned, characterizing, conversely, importantly, characterizes, revisiting, fortunately\n",
      "Topic 3 : lastly, interestingly, likewise, conversely, furthermore, aforementioned, similarly, importantly, characterizes, implying\n",
      "Topic 4 : interestingly, lastly, likewise, aforementioned, conversely, implying, importantly, characterizes, furthermore, characterizing\n",
      "Topic 5 : lastly, interestingly, likewise, fortunately, aforementioned, conversely, furthermore, unfortunately, importantly, realized\n",
      "Topic 6 : lastly, interestingly, likewise, aforementioned, fortunately, conversely, mcmahan, revisiting, importantly, smola\n",
      "Topic 7 : lastly, interestingly, likewise, aforementioned, furthermore, fortunately, conversely, importantly, unfortunately, similarly\n",
      "Topic 8 : lastly, likewise, interestingly, aforementioned, furthermore, importantly, conversely, prox, hensman, additionally\n",
      "Topic 9 : interestingly, lastly, likewise, aforementioned, conversely, furthermore, similarly, importantly, additionally, combined\n",
      "Topic 10 : lastly, likewise, interestingly, aforementioned, conversely, furthermore, fortunately, importantly, walker, consequently\n",
      "Topic 11 : lastly, likewise, interestingly, aforementioned, importantly, furthermore, conversely, fortunately, realized, unfortunately\n",
      "Topic 12 : lastly, interestingly, likewise, aforementioned, furthermore, conversely, additionally, fortunately, accordingly, revisiting\n",
      "Topic 13 : lastly, likewise, interestingly, furthermore, conversely, aforementioned, similarly, characterizes, importantly, unlike\n",
      "Topic 14 : lastly, interestingly, likewise, aforementioned, revisiting, conversely, mcmahan, fortunately, importantly, transforming\n",
      "Topic 15 : lastly, interestingly, likewise, aforementioned, furthermore, similarly, conversely, importantly, additionally, explaining\n",
      "Topic 16 : lastly, likewise, interestingly, conversely, consequently, furthermore, fortunately, replaces, importantly, posteriors\n",
      "Topic 17 : lastly, interestingly, likewise, importantly, aforementioned, conversely, furthermore, implying, fortunately, consequently\n",
      "Topic 18 : lastly, likewise, interestingly, aforementioned, conversely, hensman, importantly, explaining, mohri, characterizing\n",
      "Topic 19 : lastly, interestingly, likewise, aforementioned, conversely, similarly, importantly, characterizes, furthermore, explaining\n",
      "\n",
      "EPOCH: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:29:19.311446: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 672.46765 w2v 4.8386383 lda 667.629 reg 70.54692\n",
      "\n",
      "EPOCH: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:29:43.469645: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 600.07355 w2v 4.688328 lda 595.3852 reg 72.5656\n",
      "\n",
      "EPOCH: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:30:07.408763: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 550.36975 w2v 4.7485285 lda 545.6212 reg 74.105095\n",
      "\n",
      "EPOCH: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:30:31.482302: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 520.57904 w2v 9.0583 lda 511.52075 reg 75.264786\n",
      "\n",
      "EPOCH: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:30:55.656376: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:30:55.673104: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 494.30835 w2v 4.8089237 lda 489.49942 reg 76.0644\n",
      "---------Closest 10 words to given indexes----------\n",
      "Topic 0 : lastly, shap, respectively, deeplift, interestingly, orig, particular, combined, triplets, compute\n",
      "Topic 1 : reinforcement, summarization, recurrent, langford, volodymyr, learning, advances, aaai, nips, lstm\n",
      "Topic 2 : houdini, saliency, bounding, lastly, localisation, examples, interestingly, adversarial, perturbed, seen\n",
      "Topic 3 : lastly, consider, interestingly, similarly, given, particular, furthermore, aide, combined, comparing\n",
      "Topic 4 : sadmm, linearized, iterations, admm, interestingly, iteration, sdca, step, scheme, converge\n",
      "Topic 5 : interestingly, learnable, factorized, expressiveness, approximation, lastly, approximating, approximates, combined, approximate\n",
      "Topic 6 : rule, curran, farley, cosac, interestingly, mentioned, multiclass, histograms, clucb, consistent\n",
      "Topic 7 : interestingly, lastly, furthermore, sgd, particular, given, specifically, setting, likewise, similarly\n",
      "Topic 8 : chivi, sparse, nonconvex, klvi, hensman, bbvi, posteriors, elbo, tong, prox\n",
      "Topic 9 : interestingly, combined, lastly, aforementioned, respectively, given, similarly, note, consider, likewise\n",
      "Topic 10 : eccentricity, flankers, dcnn, configurations, dykstra, lastly, interestingly, dnns, trajgru, comprised\n",
      "Topic 11 : multitask, advances, hinton, alongside, finally, interestingly, jointly, distral, distilled, networks\n",
      "Topic 12 : accordingly, leskovec, original, addition, advances, uses, lastly, based, particular, takes\n",
      "Topic 13 : polyak, nesterov, step, following, koopman, respectively, furthermore, converge, prox, strongly\n",
      "Topic 14 : style, iccv, shapenet, cepm, reconstruction, cvpr, shading, gans, transfer, bethge\n",
      "Topic 15 : nvil, fabia, furthermore, lastly, interestingly, resulting, generalisation, specifically, stationarity, addition\n",
      "Topic 16 : dropout, lastly, optimised, autoencoder, posteriors, fits, hensman, consequently, regularize, factorized\n",
      "Topic 17 : barto, interestingly, reinforcement, consider, advances, semi, form, similarly, following, importantly\n",
      "Topic 18 : dwork, blueprint, mohri, privileged, subgame, transductive, notion, mansour, protected, hardt\n",
      "Topic 19 : lastly, interestingly, comparisons, centrality, qsgd, convert, finally, similarly, aforementioned, addition\n",
      "\n",
      "EPOCH: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:31:19.681638: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 481.4675 w2v 4.5373936 lda 476.9301 reg 76.5568\n",
      "\n",
      "EPOCH: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:31:43.391212: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 475.89566 w2v 5.2147703 lda 470.68088 reg 76.86433\n",
      "\n",
      "EPOCH: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:32:07.312596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 473.04968 w2v 4.9652762 lda 468.0844 reg 77.04257\n",
      "\n",
      "EPOCH: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:32:31.254386: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 472.44748 w2v 5.259681 lda 467.1878 reg 77.12603\n",
      "\n",
      "EPOCH: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:32:55.260328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:32:55.277387: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 472.6991 w2v 5.877225 lda 466.82187 reg 77.16852\n",
      "---------Closest 10 words to given indexes----------\n",
      "Topic 0 : shap, orig, respectively, jaitly, deeplift, lime, particular, adjustable, triplets, weston\n",
      "Topic 1 : sherjil, lanctot, volodymyr, reinforcement, abadie, jaitly, dauphin, aaai, learning, yoshua\n",
      "Topic 2 : houdini, saliency, localisation, imagenet, bounding, masks, probit, examples, masking, attacks\n",
      "Topic 3 : consider, given, bound, note, respectively, particular, shown, advances, auxiliary, following\n",
      "Topic 4 : sadmm, sdca, linearized, admm, jimmy, iterations, iteration, variants, multipliers, penalty\n",
      "Topic 5 : factorized, approximation, expressiveness, jaitly, icml, learnable, breiman, approximates, bilmes, curran\n",
      "Topic 6 : farley, ozair, warde, sherjil, abadie, rule, cosac, curran, langford, consistent\n",
      "Topic 7 : ozair, given, learning, lmax, nips, farley, yoshua, sherjil, bound, advances\n",
      "Topic 8 : chivi, ranganath, klvi, nonconvex, sparse, tong, elbo, regularizer, sandwich, advances\n",
      "Topic 9 : respectively, bound, given, note, adaptation, advances, curran, semi, lecun, ozair\n",
      "Topic 10 : eccentricity, flankers, imitation, configurations, dcnn, psgd, flanker, trajgru, convgru, spacing\n",
      "Topic 11 : hinton, volodymyr, distilled, advances, multitask, learning, distral, sherjil, imagenet, farley\n",
      "Topic 12 : advances, learning, neural, based, shown, jaitly, given, second, bordes, uses\n",
      "Topic 13 : nesterov, polyak, koopman, step, following, accelerated, respectively, prox, monotonicity, note\n",
      "Topic 14 : ozair, style, farley, iccv, shapenet, cvpr, reconstruction, sherjil, bethge, abadie\n",
      "Topic 15 : fabia, nvil, given, mixture, jaitly, nips, advances, smola, bound, shown\n",
      "Topic 16 : dropout, aleatoric, unrolled, epistemic, optimised, autoencoder, abadie, disparate, lastly, hensman\n",
      "Topic 17 : barto, reinforcement, learning, semi, advances, note, consider, given, conference, suppose\n",
      "Topic 18 : dwork, mansour, equalized, transductive, blueprint, privileged, blum, protected, hardt, koren\n",
      "Topic 19 : centrality, qsgd, jaitly, given, frey, comparisons, note, nips, convert, bordes\n",
      "\n",
      "EPOCH: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:33:19.331513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 471.00015 w2v 4.46276 lda 466.53738 reg 77.20459\n",
      "\n",
      "EPOCH: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:33:43.543690: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 471.22665 w2v 4.8019834 lda 466.42468 reg 77.23213\n",
      "\n",
      "EPOCH: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:34:07.784889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 472.79224 w2v 6.372525 lda 466.4197 reg 77.260284\n",
      "\n",
      "EPOCH: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:34:31.693028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 471.3507 w2v 4.930955 lda 466.41974 reg 77.27841\n",
      "\n",
      "EPOCH: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:34:55.613339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:34:55.630892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 470.65054 w2v 4.230844 lda 466.4197 reg 77.29014\n",
      "---------Closest 10 words to given indexes----------\n",
      "Topic 0 : orig, jaitly, koray, lime, sherjil, shap, diederik, kavukcuoglu, adjustable, respectively\n",
      "Topic 1 : sherjil, lanctot, abadie, volodymyr, rusu, veness, kavukcuoglu, koray, yoshua, jaitly\n",
      "Topic 2 : houdini, saliency, localisation, imagenet, probit, attacks, ozair, masks, masking, adversarial\n",
      "Topic 3 : consider, given, bound, advances, note, shown, following, respectively, auxiliary, nips\n",
      "Topic 4 : sadmm, sdca, linearized, admm, jimmy, iterations, entailment, diederik, xiong, adam\n",
      "Topic 5 : factorized, jaitly, curran, approximation, bilmes, icml, ozair, warde, breiman, sherjil\n",
      "Topic 6 : ozair, farley, warde, sherjil, abadie, osindero, mirza, dumoulin, mehdi, curran\n",
      "Topic 7 : ozair, sherjil, warde, yoshua, farley, entailment, rusu, given, nips, learning\n",
      "Topic 8 : chivi, ranganath, nonconvex, tong, klvi, sandwich, sparse, advances, abadie, ozair\n",
      "Topic 9 : entailment, ozair, warde, bound, semi, advances, curran, adaptation, jaitly, given\n",
      "Topic 10 : eccentricity, flankers, spacing, imitation, shaoqing, configurations, batchnorm, flanker, mastering, entailment\n",
      "Topic 11 : volodymyr, hinton, sherjil, pascanu, farley, advances, ozair, shaoqing, learning, multitask\n",
      "Topic 12 : advances, learning, neural, ozair, haffner, entailment, jaitly, ndcg, warde, based\n",
      "Topic 13 : koopman, nesterov, polyak, step, sherjil, following, accelerated, lkis, ozair, warde\n",
      "Topic 14 : ozair, farley, sherjil, style, iccv, abadie, cvpr, warde, shapenet, reconstruction\n",
      "Topic 15 : fabia, nvil, jaitly, nips, mixture, advances, entailment, ozair, rusu, given\n",
      "Topic 16 : abadie, sherjil, dropout, ozair, diederik, shakir, mehdi, disparate, warde, unrolled\n",
      "Topic 17 : entailment, barto, sherjil, koren, learning, advances, ozair, semi, abadie, reinforcement\n",
      "Topic 18 : koren, dwork, equalized, mansour, blueprint, kearns, auer, protected, nicol, bubeck\n",
      "Topic 19 : centrality, jaitly, entailment, qsgd, frey, volodymyr, sherjil, haffner, nips, curran\n",
      "\n",
      "EPOCH: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:35:19.832004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 471.6653 w2v 5.245599 lda 466.4197 reg 77.307495\n",
      "\n",
      "EPOCH: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:35:43.927247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 470.96753 w2v 4.5478115 lda 466.4197 reg 77.328964\n",
      "\n",
      "EPOCH: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:36:08.010371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 470.8659 w2v 4.446199 lda 466.4197 reg 77.34604\n",
      "\n",
      "EPOCH: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:36:32.079418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 472.03183 w2v 5.6121206 lda 466.4197 reg 77.34589\n",
      "\n",
      "EPOCH: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:36:56.442789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-11-20 00:36:56.461123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS 470.79916 w2v 4.3794374 lda 466.41974 reg 77.34739\n",
      "---------Closest 10 words to given indexes----------\n",
      "Topic 0 : orig, koray, sherjil, jaitly, entailment, mirza, kavukcuoglu, adjustable, xiangyu, diederik\n",
      "Topic 1 : sherjil, lanctot, abadie, koray, rusu, veness, volodymyr, antonoglou, hassabis, guez\n",
      "Topic 2 : saliency, houdini, imagenet, ozair, localisation, xiangyu, entailment, attacks, jaitly, abadie\n",
      "Topic 3 : abadie, bound, note, sherjil, given, consider, citro, mirza, entailment, ozair\n",
      "Topic 4 : sdca, sadmm, admm, entailment, jimmy, linearized, abadie, kingma, shakir, diederik\n",
      "Topic 5 : jaitly, sherjil, warde, curran, ozair, bilmes, factorized, abadie, florina, icml\n",
      "Topic 6 : ozair, farley, sherjil, warde, abadie, mirza, dumoulin, mehdi, osindero, veness\n",
      "Topic 7 : ozair, sherjil, entailment, warde, rusu, farley, antonoglou, abadie, mastering, koren\n",
      "Topic 8 : ranganath, sherjil, chivi, abadie, nonconvex, lafferty, warde, ozair, tong, danilo\n",
      "Topic 9 : entailment, warde, ozair, jaitly, sherjil, rusu, abadie, citro, bound, mehdi\n",
      "Topic 10 : entailment, hassabis, eccentricity, mastering, flankers, flanker, shaoqing, batchnorm, karen, guez\n",
      "Topic 11 : sherjil, volodymyr, hinton, abadie, koray, farley, veness, ozair, warde, mirza\n",
      "Topic 12 : entailment, sherjil, ozair, warde, jaitly, rusu, advances, haffner, neural, learning\n",
      "Topic 13 : sherjil, koopman, nesterov, warde, entailment, polyak, step, ozair, following, lkis\n",
      "Topic 14 : ozair, sherjil, farley, abadie, warde, entailment, style, iccv, dumoulin, shapenet\n",
      "Topic 15 : fabia, entailment, rusu, jaitly, nvil, ozair, sherjil, warde, citro, mixture\n",
      "Topic 16 : sherjil, abadie, shakir, ozair, entailment, mehdi, warde, diederik, danilo, mirza\n",
      "Topic 17 : entailment, sherjil, koren, shakir, abadie, ozair, mirza, antonoglou, mehdi, warde\n",
      "Topic 18 : koren, equalized, kearns, ijcai, abadie, dwork, sherjil, protected, bubeck, warde\n",
      "Topic 19 : entailment, jaitly, sherjil, brevdo, citro, centrality, volodymyr, barham, shakir, frey\n",
      "\n",
      "EPOCH: 26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/xpt23s1j08vd186gztkz58700000gn/T/ipykernel_19477/1543583293.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m m.train(pivot_ids,\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdoc_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Computer_Science/Comp_755/project/code/./Lda2vec-Tensorflow-master/lda2vec/Lda2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, pivot_words, target_words, doc_ids, data_size, num_epochs, switch_loss_epoch, save_every, report_every, print_topics_every, idx_to_word)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# Run a step of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "m.train(pivot_ids,\n",
    "        target_ids,\n",
    "        doc_ids,\n",
    "        len(pivot_ids),\n",
    "        num_epochs,\n",
    "        idx_to_word=idx_to_word,\n",
    "        switch_loss_epoch=switch_loss_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzdVCxyOSd-s"
   },
   "source": [
    "## Get Word and Topic Embeddings\n",
    "\n",
    "Visualize topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2itPKBHwEmyf",
    "outputId": "8e1667af-ee91-4a94-c9b1-ffde52293b44",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'learning',\n",
       " 2: 'model',\n",
       " 3: 'data',\n",
       " 4: 'algorithm',\n",
       " 5: 'function',\n",
       " 6: 'neural',\n",
       " 7: 'time',\n",
       " 8: 'training',\n",
       " 9: 'problem',\n",
       " 10: 'information',\n",
       " 11: 'results',\n",
       " 12: 'number',\n",
       " 13: 'distribution',\n",
       " 14: 'models',\n",
       " 15: 'networks',\n",
       " 16: 'network',\n",
       " 17: 'based',\n",
       " 18: 'figure',\n",
       " 19: 'methods',\n",
       " 20: 'matrix',\n",
       " 21: 'method',\n",
       " 22: 'given',\n",
       " 23: 'algorithms',\n",
       " 24: 'pages',\n",
       " 25: 'different',\n",
       " 26: 'gradient',\n",
       " 27: 'arxiv',\n",
       " 28: 'performance',\n",
       " 29: 'loss',\n",
       " 30: 'optimization',\n",
       " 31: 'linear',\n",
       " 32: 'work',\n",
       " 33: 'section',\n",
       " 34: 'image',\n",
       " 35: 'error',\n",
       " 36: 'approach',\n",
       " 37: 'case',\n",
       " 38: 'theorem',\n",
       " 39: 'deep',\n",
       " 40: 'state',\n",
       " 41: 'random',\n",
       " 42: 'bound',\n",
       " 43: 'conference',\n",
       " 44: 'machine',\n",
       " 45: 'optimal',\n",
       " 46: 'systems',\n",
       " 47: 'probability',\n",
       " 48: 'parameters',\n",
       " 49: 'functions',\n",
       " 50: 'large',\n",
       " 51: 'following',\n",
       " 52: 'input',\n",
       " 53: 'space',\n",
       " 54: 'samples',\n",
       " 55: 'analysis',\n",
       " 56: 'processing',\n",
       " 57: 'size',\n",
       " 58: 'value',\n",
       " 59: 'sample',\n",
       " 60: 'convex',\n",
       " 61: 'stochastic',\n",
       " 62: 'proposed',\n",
       " 63: 'dataset',\n",
       " 64: 'task',\n",
       " 65: 'layer',\n",
       " 66: 'order',\n",
       " 67: 'kernel',\n",
       " 68: 'policy',\n",
       " 69: 'features',\n",
       " 70: 'vector',\n",
       " 71: 'step',\n",
       " 72: 'inference',\n",
       " 73: 'approximation',\n",
       " 74: 'test',\n",
       " 75: 'consider',\n",
       " 76: 'gaussian',\n",
       " 77: 'experiments',\n",
       " 78: 'example',\n",
       " 79: 'note',\n",
       " 80: 'point',\n",
       " 81: 'high',\n",
       " 82: 'setting',\n",
       " 83: 'paper',\n",
       " 84: 'convergence',\n",
       " 85: 'output',\n",
       " 86: 'rate',\n",
       " 87: 'feature',\n",
       " 88: 'classification',\n",
       " 89: 'values',\n",
       " 90: 'process',\n",
       " 91: 'accuracy',\n",
       " 92: 'problems',\n",
       " 93: 'objective',\n",
       " 94: 'parameter',\n",
       " 95: 'images',\n",
       " 96: 'sampling',\n",
       " 97: 'noise',\n",
       " 98: 'graph',\n",
       " 99: 'complexity',\n",
       " 100: 'class',\n",
       " 101: 'prediction',\n",
       " 102: 'estimation',\n",
       " 103: 'table',\n",
       " 104: 'defined',\n",
       " 105: 'lower',\n",
       " 106: 'international',\n",
       " 107: 'regression',\n",
       " 108: 'mean',\n",
       " 109: 'small',\n",
       " 110: 'general',\n",
       " 111: 'points',\n",
       " 112: 'standard',\n",
       " 113: 'result',\n",
       " 114: 'solution',\n",
       " 115: 'similar',\n",
       " 116: 'cost',\n",
       " 117: 'single',\n",
       " 118: 'bounds',\n",
       " 119: 'proceedings',\n",
       " 120: 'preprint',\n",
       " 121: 'latent',\n",
       " 122: 'variables',\n",
       " 123: 'learn',\n",
       " 124: 'form',\n",
       " 125: 'better',\n",
       " 126: 'tasks',\n",
       " 127: 'real',\n",
       " 128: 'trained',\n",
       " 129: 'datasets',\n",
       " 130: 'second',\n",
       " 131: 'sequence',\n",
       " 132: 'multi',\n",
       " 133: 'structure',\n",
       " 134: 'distributions',\n",
       " 135: 'shown',\n",
       " 136: 'research',\n",
       " 137: 'best',\n",
       " 138: 'ieee',\n",
       " 139: 'lemma',\n",
       " 140: 'journal',\n",
       " 141: 'regret',\n",
       " 142: 'nips',\n",
       " 143: 'assume',\n",
       " 144: 'rank',\n",
       " 145: 'shows',\n",
       " 146: 'generative',\n",
       " 147: 'true',\n",
       " 148: 'variational',\n",
       " 149: 'framework',\n",
       " 150: 'theory',\n",
       " 151: 'fixed',\n",
       " 152: 'long',\n",
       " 153: 'scale',\n",
       " 154: 'dimensional',\n",
       " 155: 'approximate',\n",
       " 156: 'estimate',\n",
       " 157: 'adversarial',\n",
       " 158: 'term',\n",
       " 159: 'empirical',\n",
       " 160: 'convolutional',\n",
       " 161: 'simple',\n",
       " 162: 'weights',\n",
       " 163: 'proof',\n",
       " 164: 'possible',\n",
       " 165: 'layers',\n",
       " 166: 'average',\n",
       " 167: 'norm',\n",
       " 168: 'known',\n",
       " 169: 'advances',\n",
       " 170: 'constant',\n",
       " 171: 'sparse',\n",
       " 172: 'reward',\n",
       " 173: 'denote',\n",
       " 174: 'prior',\n",
       " 175: 'variance',\n",
       " 176: 'posterior',\n",
       " 177: 'computer',\n",
       " 178: 'descent',\n",
       " 179: 'examples',\n",
       " 180: 'terms',\n",
       " 181: 'corresponding',\n",
       " 182: 'distance',\n",
       " 183: 'level',\n",
       " 184: 'follows',\n",
       " 185: 'statistical',\n",
       " 186: 'recognition',\n",
       " 187: 'efficient',\n",
       " 188: 'computational',\n",
       " 189: 'online',\n",
       " 190: 'domain',\n",
       " 191: 'define',\n",
       " 192: 'local',\n",
       " 193: 'estimator',\n",
       " 194: 'update',\n",
       " 195: 'obtain',\n",
       " 196: 'approaches',\n",
       " 197: 'multiple',\n",
       " 198: 'particular',\n",
       " 199: 'target',\n",
       " 200: 'related',\n",
       " 201: 'bayesian',\n",
       " 202: 'variable',\n",
       " 203: 'batch',\n",
       " 204: 'compute',\n",
       " 205: 'iteration',\n",
       " 206: 'provide',\n",
       " 207: 'assumption',\n",
       " 208: 'action',\n",
       " 209: 'university',\n",
       " 210: 'previous',\n",
       " 211: 'clustering',\n",
       " 212: 'representation',\n",
       " 213: 'natural',\n",
       " 214: 'computation',\n",
       " 215: 'independent',\n",
       " 216: 'condition',\n",
       " 217: 'likelihood',\n",
       " 218: 'applications',\n",
       " 219: 'nodes',\n",
       " 220: 'fig',\n",
       " 221: 'appendix',\n",
       " 222: 'propose',\n",
       " 223: 'continuous',\n",
       " 224: 'train',\n",
       " 225: 'system',\n",
       " 226: 'respectively',\n",
       " 227: 'representations',\n",
       " 228: 'obtained',\n",
       " 229: 'label',\n",
       " 230: 'weight',\n",
       " 231: 'expected',\n",
       " 232: 'vectors',\n",
       " 233: 'attention',\n",
       " 234: 'learned',\n",
       " 235: 'generated',\n",
       " 236: 'conditional',\n",
       " 237: 'applied',\n",
       " 238: 'instead',\n",
       " 239: 'knowledge',\n",
       " 240: 'node',\n",
       " 241: 'zero',\n",
       " 242: 'theoretical',\n",
       " 243: 'agent',\n",
       " 244: 'positive',\n",
       " 245: 'comparison',\n",
       " 246: 'observed',\n",
       " 247: 'search',\n",
       " 248: 'sets',\n",
       " 249: 'maximum',\n",
       " 250: 'object',\n",
       " 251: 'control',\n",
       " 252: 'upper',\n",
       " 253: 'original',\n",
       " 254: 'matrices',\n",
       " 255: 'memory',\n",
       " 256: 'supervised',\n",
       " 257: 'computing',\n",
       " 258: 'compared',\n",
       " 259: 'like',\n",
       " 260: 'density',\n",
       " 261: 'find',\n",
       " 262: 'binary',\n",
       " 263: 'statistics',\n",
       " 264: 'bounded',\n",
       " 265: 'present',\n",
       " 266: 'factor',\n",
       " 267: 'labels',\n",
       " 268: 'definition',\n",
       " 269: 'iterations',\n",
       " 270: 'dynamics',\n",
       " 271: 'main',\n",
       " 272: 'need',\n",
       " 273: 'recent',\n",
       " 274: 'human',\n",
       " 275: 'architecture',\n",
       " 276: 'goal',\n",
       " 277: 'regularization',\n",
       " 278: 'compare',\n",
       " 279: 'classifier',\n",
       " 280: 'right',\n",
       " 281: 'embedding',\n",
       " 282: 'good',\n",
       " 283: 'hidden',\n",
       " 284: 'left',\n",
       " 285: 'selection',\n",
       " 286: 'directly',\n",
       " 287: 'requires',\n",
       " 288: 'visual',\n",
       " 289: 'properties',\n",
       " 290: 'steps',\n",
       " 291: 'respect',\n",
       " 292: 'dimension',\n",
       " 293: 'guarantees',\n",
       " 294: 'tree',\n",
       " 295: 'study',\n",
       " 296: 'uses',\n",
       " 297: 'states',\n",
       " 298: 'specific',\n",
       " 299: 'perform',\n",
       " 300: 'means',\n",
       " 301: 'future',\n",
       " 302: 'design',\n",
       " 303: 'science',\n",
       " 304: 'additional',\n",
       " 305: 'instance',\n",
       " 306: 'finite',\n",
       " 307: 'metric',\n",
       " 308: 'fast',\n",
       " 309: 'baseline',\n",
       " 310: 'context',\n",
       " 311: 'decision',\n",
       " 312: 'measure',\n",
       " 313: 'techniques',\n",
       " 314: 'achieve',\n",
       " 315: 'found',\n",
       " 316: 'processes',\n",
       " 317: 'discrete',\n",
       " 318: 'practice',\n",
       " 319: 'observations',\n",
       " 320: 'equation',\n",
       " 321: 'modeling',\n",
       " 322: 'details',\n",
       " 323: 'evaluation',\n",
       " 324: 'group',\n",
       " 325: 'reinforcement',\n",
       " 326: 'fact',\n",
       " 327: 'total',\n",
       " 328: 'risk',\n",
       " 329: 'negative',\n",
       " 330: 'robust',\n",
       " 331: 'significantly',\n",
       " 332: 'vision',\n",
       " 333: 'finally',\n",
       " 334: 'available',\n",
       " 335: 'procedure',\n",
       " 336: 'important',\n",
       " 337: 'constraints',\n",
       " 338: 'current',\n",
       " 339: 'initial',\n",
       " 340: 'computed',\n",
       " 341: 'adaptive',\n",
       " 342: 'cases',\n",
       " 343: 'apply',\n",
       " 344: 'joint',\n",
       " 345: 'recurrent',\n",
       " 346: 'covariance',\n",
       " 347: 'rates',\n",
       " 348: 'zhang',\n",
       " 349: 'higher',\n",
       " 350: 'strategy',\n",
       " 351: 'works',\n",
       " 352: 'distributed',\n",
       " 353: 'experiment',\n",
       " 354: 'generalization',\n",
       " 355: 'choice',\n",
       " 356: 'markov',\n",
       " 357: 'allows',\n",
       " 358: 'introduction',\n",
       " 359: 'ground',\n",
       " 360: 'question',\n",
       " 361: 'evaluate',\n",
       " 362: 'matching',\n",
       " 363: 'score',\n",
       " 364: 'constraint',\n",
       " 365: 'global',\n",
       " 366: 'icml',\n",
       " 367: 'signal',\n",
       " 368: 'conditions',\n",
       " 369: 'mnist',\n",
       " 370: 'larger',\n",
       " 371: 'subset',\n",
       " 372: 'classes',\n",
       " 373: 'game',\n",
       " 374: 'complex',\n",
       " 375: 'assumptions',\n",
       " 376: 'able',\n",
       " 377: 'observation',\n",
       " 378: 'supplementary',\n",
       " 379: 'estimates',\n",
       " 380: 'uniform',\n",
       " 381: 'generator',\n",
       " 382: 'version',\n",
       " 383: 'including',\n",
       " 384: 'fully',\n",
       " 385: 'spectral',\n",
       " 386: 'gradients',\n",
       " 387: 'difference',\n",
       " 388: 'lstm',\n",
       " 389: 'times',\n",
       " 390: 'exact',\n",
       " 391: 'language',\n",
       " 392: 'observe',\n",
       " 393: 'according',\n",
       " 394: 'specifically',\n",
       " 395: 'discriminator',\n",
       " 396: 'solving',\n",
       " 397: 'demonstrate',\n",
       " 398: 'support',\n",
       " 399: 'hand',\n",
       " 400: 'settings',\n",
       " 401: 'solve',\n",
       " 402: 'require',\n",
       " 403: 'minimization',\n",
       " 404: 'rule',\n",
       " 405: 'product',\n",
       " 406: 'uncertainty',\n",
       " 407: 'called',\n",
       " 408: 'tensor',\n",
       " 409: 'improve',\n",
       " 410: 'denotes',\n",
       " 411: 'provides',\n",
       " 412: 'described',\n",
       " 413: 'existing',\n",
       " 414: 'synthetic',\n",
       " 415: 'truth',\n",
       " 416: 'introduce',\n",
       " 417: 'quality',\n",
       " 418: 'abstract',\n",
       " 419: 'wang',\n",
       " 420: 'predictions',\n",
       " 421: 'exponential',\n",
       " 422: 'world',\n",
       " 423: 'provided',\n",
       " 424: 'contains',\n",
       " 425: 'david',\n",
       " 426: 'noisy',\n",
       " 427: 'divergence',\n",
       " 428: 'expectation',\n",
       " 429: 'user',\n",
       " 430: 'intelligence',\n",
       " 431: 'elements',\n",
       " 432: 'focus',\n",
       " 433: 'close',\n",
       " 434: 'generate',\n",
       " 435: 'line',\n",
       " 436: 'experimental',\n",
       " 437: 'graphs',\n",
       " 438: 'block',\n",
       " 439: 'outputs',\n",
       " 440: 'novel',\n",
       " 441: 'inputs',\n",
       " 442: 'pattern',\n",
       " 443: 'polynomial',\n",
       " 444: 'property',\n",
       " 445: 'policies',\n",
       " 446: 'family',\n",
       " 447: 'structured',\n",
       " 448: 'common',\n",
       " 449: 'encoder',\n",
       " 450: 'bias',\n",
       " 451: 'cross',\n",
       " 452: 'holds',\n",
       " 453: 'estimated',\n",
       " 454: 'embeddings',\n",
       " 455: 'coordinate',\n",
       " 456: 'detection',\n",
       " 457: 'scheme',\n",
       " 458: 'submodular',\n",
       " 459: 'contrast',\n",
       " 460: 'unknown',\n",
       " 461: 'words',\n",
       " 462: 'validation',\n",
       " 463: 'smooth',\n",
       " 464: 'references',\n",
       " 465: 'volume',\n",
       " 466: 'cifar',\n",
       " 467: 'reduction',\n",
       " 468: 'games',\n",
       " 469: 'behavior',\n",
       " 470: 'semi',\n",
       " 471: 'artificial',\n",
       " 472: 'length',\n",
       " 473: 'dynamic',\n",
       " 474: 'actions',\n",
       " 475: 'pairs',\n",
       " 476: 'range',\n",
       " 477: 'flow',\n",
       " 478: 'considered',\n",
       " 479: 'kernels',\n",
       " 480: 'faster',\n",
       " 481: 'smaller',\n",
       " 482: 'transition',\n",
       " 483: 'individual',\n",
       " 484: 'strong',\n",
       " 485: 'nonlinear',\n",
       " 486: 'satisfies',\n",
       " 487: 'hard',\n",
       " 488: 'effect',\n",
       " 489: 'components',\n",
       " 490: 'sampled',\n",
       " 491: 'achieves',\n",
       " 492: 'material',\n",
       " 493: 'region',\n",
       " 494: 'recently',\n",
       " 495: 'chen',\n",
       " 496: 'resulting',\n",
       " 497: 'chosen',\n",
       " 498: 'phase',\n",
       " 499: 'addition',\n",
       " 500: 'cluster',\n",
       " 501: 'transfer',\n",
       " 502: 'operator',\n",
       " 503: 'equal',\n",
       " 504: 'exists',\n",
       " 505: 'effective',\n",
       " 506: 'type',\n",
       " 507: 'final',\n",
       " 508: 'randomly',\n",
       " 509: 'temporal',\n",
       " 510: 'associated',\n",
       " 511: 'units',\n",
       " 512: 'application',\n",
       " 513: 'threshold',\n",
       " 514: 'unsupervised',\n",
       " 515: 'objects',\n",
       " 516: 'oracle',\n",
       " 517: 'hierarchical',\n",
       " 518: 'ratio',\n",
       " 519: 'prove',\n",
       " 520: 'usa',\n",
       " 521: 'mapping',\n",
       " 522: 'architectures',\n",
       " 523: 'underlying',\n",
       " 524: 'typically',\n",
       " 525: 'series',\n",
       " 526: 'corresponds',\n",
       " 527: 'hypothesis',\n",
       " 528: 'programming',\n",
       " 529: 'edges',\n",
       " 530: 'depends',\n",
       " 531: 'edge',\n",
       " 532: 'suppose',\n",
       " 533: 'connected',\n",
       " 534: 'unit',\n",
       " 535: 'greedy',\n",
       " 536: 'equivalent',\n",
       " 537: 'dropout',\n",
       " 538: 'mixture',\n",
       " 539: 'presented',\n",
       " 540: 'probabilistic',\n",
       " 541: 'introduced',\n",
       " 542: 'testing',\n",
       " 543: 'code',\n",
       " 544: 'consistent',\n",
       " 545: 'direction',\n",
       " 546: 'predict',\n",
       " 547: 'residual',\n",
       " 548: 'required',\n",
       " 549: 'guarantee',\n",
       " 550: 'entropy',\n",
       " 551: 'relative',\n",
       " 552: 'significant',\n",
       " 553: 'improved',\n",
       " 554: 'pair',\n",
       " 555: 'potential',\n",
       " 556: 'strongly',\n",
       " 557: 'running',\n",
       " 558: 'arbitrary',\n",
       " 559: 'maps',\n",
       " 560: 'furthermore',\n",
       " 561: 'clusters',\n",
       " 562: 'beach',\n",
       " 563: 'idea',\n",
       " 564: 'depth',\n",
       " 565: 'updates',\n",
       " 566: 'decoder',\n",
       " 567: 'springer',\n",
       " 568: 'choose',\n",
       " 569: 'deterministic',\n",
       " 570: 'formulation',\n",
       " 571: 'query',\n",
       " 572: 'inverse',\n",
       " 573: 'confidence',\n",
       " 574: 'similarity',\n",
       " 575: 'weighted',\n",
       " 576: 'importance',\n",
       " 577: 'bandit',\n",
       " 578: 'path',\n",
       " 579: 'stage',\n",
       " 580: 'outperforms',\n",
       " 581: 'sequential',\n",
       " 582: 'word',\n",
       " 583: 'bengio',\n",
       " 584: 'decomposition',\n",
       " 585: 'dual',\n",
       " 586: 'makes',\n",
       " 587: 'reduce',\n",
       " 588: 'power',\n",
       " 589: 'component',\n",
       " 590: 'leads',\n",
       " 591: 'seen',\n",
       " 592: 'change',\n",
       " 593: 'takes',\n",
       " 594: 'sequences',\n",
       " 595: 'influence',\n",
       " 596: 'free',\n",
       " 597: 'report',\n",
       " 598: 'sparsity',\n",
       " 599: 'literature',\n",
       " 600: 'adam',\n",
       " 601: 'minimum',\n",
       " 602: 'improvement',\n",
       " 603: 'projection',\n",
       " 604: 'supported',\n",
       " 605: 'transactions',\n",
       " 606: 'studied',\n",
       " 607: 'environment',\n",
       " 608: 'spatial',\n",
       " 609: 'implies',\n",
       " 610: 'brain',\n",
       " 611: 'predictive',\n",
       " 612: 'text',\n",
       " 613: 'generalized',\n",
       " 614: 'measures',\n",
       " 615: 'reconstruction',\n",
       " 616: 'accurate',\n",
       " 617: 'active',\n",
       " 618: 'domains',\n",
       " 619: 'consists',\n",
       " 620: 'represent',\n",
       " 621: 'segmentation',\n",
       " 622: 'source',\n",
       " 623: 'causal',\n",
       " 624: 'refer',\n",
       " 625: 'column',\n",
       " 626: 'making',\n",
       " 627: 'proc',\n",
       " 628: 'player',\n",
       " 629: 'parallel',\n",
       " 630: 'interest',\n",
       " 631: 'minimizing',\n",
       " 632: 'feedback',\n",
       " 633: 'translation',\n",
       " 634: 'drawn',\n",
       " 635: 'practical',\n",
       " 636: 'dependent',\n",
       " 637: 'similarly',\n",
       " 638: 'initialization',\n",
       " 639: 'include',\n",
       " 640: 'implementation',\n",
       " 641: 'gives',\n",
       " 642: 'performs',\n",
       " 643: 'solutions',\n",
       " 644: 'estimating',\n",
       " 645: 'instances',\n",
       " 646: 'technique',\n",
       " 647: 'applying',\n",
       " 648: 'selected',\n",
       " 649: 'simply',\n",
       " 650: 'precision',\n",
       " 651: 'recovery',\n",
       " 652: 'marginal',\n",
       " 653: 'invariant',\n",
       " 654: 'achieved',\n",
       " 655: 'minimize',\n",
       " 656: 'generation',\n",
       " 657: 'press',\n",
       " 658: 'proposition',\n",
       " 659: 'certain',\n",
       " 660: 'exploration',\n",
       " 661: 'correlation',\n",
       " 662: 'michael',\n",
       " 663: 'denoted',\n",
       " 664: 'performed',\n",
       " 665: 'errors',\n",
       " 666: 'agents',\n",
       " 667: 'mini',\n",
       " 668: 'recall',\n",
       " 669: 'quadratic',\n",
       " 670: 'normalization',\n",
       " 671: 'start',\n",
       " 672: 'relu',\n",
       " 673: 'difficult',\n",
       " 674: 'rules',\n",
       " 675: 'entries',\n",
       " 676: 'useful',\n",
       " 677: 'carlo',\n",
       " 678: 'produce',\n",
       " 679: 'nature',\n",
       " 680: 'forward',\n",
       " 681: 'grid',\n",
       " 682: 'overall',\n",
       " 683: 'numerical',\n",
       " 684: 'softmax',\n",
       " 685: 'finding',\n",
       " 686: 'monte',\n",
       " 687: 'gans',\n",
       " 688: 'rewards',\n",
       " 689: 'stationary',\n",
       " 690: 'energy',\n",
       " 691: 'special',\n",
       " 692: 'construct',\n",
       " 693: 'neurons',\n",
       " 694: 'inequality',\n",
       " 695: 'set',\n",
       " 696: 'increases',\n",
       " 697: 'graphical',\n",
       " 698: 'probabilities',\n",
       " 699: 'lipschitz',\n",
       " 700: 'element',\n",
       " 701: 'squared',\n",
       " 702: 'sufficient',\n",
       " 703: 'video',\n",
       " 704: 'uniformly',\n",
       " 705: 'field',\n",
       " 706: 'round',\n",
       " 707: 'efficiently',\n",
       " 708: 'address',\n",
       " 709: 'increasing',\n",
       " 710: 'transformation',\n",
       " 711: 'derive',\n",
       " 712: 'stability',\n",
       " 713: 'efficiency',\n",
       " 714: 'exactly',\n",
       " 715: 'labeled',\n",
       " 716: 'wise',\n",
       " 717: 'yields',\n",
       " 718: 'users',\n",
       " 719: 'interesting',\n",
       " 720: 'maximization',\n",
       " 721: 'view',\n",
       " 722: 'vol',\n",
       " 723: 'near',\n",
       " 724: 'represents',\n",
       " 725: 'stable',\n",
       " 726: 'trajectories',\n",
       " 727: 'allow',\n",
       " 728: 'describe',\n",
       " 729: 'annual',\n",
       " 730: 'basis',\n",
       " 731: 'queries',\n",
       " 732: 'cvpr',\n",
       " 733: 'factors',\n",
       " 734: 'mathematical',\n",
       " 735: 'parametric',\n",
       " 736: 'response',\n",
       " 737: 'predicted',\n",
       " 738: 'converges',\n",
       " 739: 'ranking',\n",
       " 740: 'consistency',\n",
       " 741: 'degree',\n",
       " 742: 'estimators',\n",
       " 743: 'communication',\n",
       " 744: 'split',\n",
       " 745: 'types',\n",
       " 746: 'regularized',\n",
       " 747: 'convolution',\n",
       " 748: 'corr',\n",
       " 749: 'lead',\n",
       " 750: 'notation',\n",
       " 751: 'scores',\n",
       " 752: 'necessary',\n",
       " 753: 'differentiable',\n",
       " 754: 'additive',\n",
       " 755: 'satisfy',\n",
       " 756: 'explicitly',\n",
       " 757: 'approximately',\n",
       " 758: 'filter',\n",
       " 759: 'self',\n",
       " 760: 'center',\n",
       " 761: 'review',\n",
       " 762: 'activation',\n",
       " 763: 'taking',\n",
       " 764: 'corollary',\n",
       " 765: 'learns',\n",
       " 766: 'improves',\n",
       " 767: 'alternative',\n",
       " 768: 'location',\n",
       " 769: 'partition',\n",
       " 770: 'understanding',\n",
       " 771: 'expert',\n",
       " 772: 'http',\n",
       " 773: 'depend',\n",
       " 774: 'capture',\n",
       " 775: 'generating',\n",
       " 776: 'items',\n",
       " 777: 'dimensions',\n",
       " 778: 'optimize',\n",
       " 779: 'sizes',\n",
       " 780: 'tuning',\n",
       " 781: 'converge',\n",
       " 782: 'increase',\n",
       " 783: 'highly',\n",
       " 784: 'constrained',\n",
       " 785: 'mechanism',\n",
       " 786: 'derived',\n",
       " 787: 'classifiers',\n",
       " 788: 'basic',\n",
       " 789: 'variant',\n",
       " 790: 'easily',\n",
       " 791: 'hold',\n",
       " 792: 'pixel',\n",
       " 793: 'setup',\n",
       " 794: 'speed',\n",
       " 795: 'base',\n",
       " 796: 'discussed',\n",
       " 797: 'ability',\n",
       " 798: 'normalized',\n",
       " 799: 'planning',\n",
       " 800: 'partial',\n",
       " 801: 'challenging',\n",
       " 802: 'correct',\n",
       " 803: 'benchmark',\n",
       " 804: 'columns',\n",
       " 805: 'john',\n",
       " 806: 'siam',\n",
       " 807: 'strategies',\n",
       " 808: 'population',\n",
       " 809: 'classical',\n",
       " 810: 'margin',\n",
       " 811: 'limited',\n",
       " 812: 'usually',\n",
       " 813: 'operations',\n",
       " 814: 'losses',\n",
       " 815: 'dependence',\n",
       " 816: 'connections',\n",
       " 817: 'studies',\n",
       " 818: 'discussion',\n",
       " 819: 'develop',\n",
       " 820: 'recover',\n",
       " 821: 'encoding',\n",
       " 822: 'symmetric',\n",
       " 823: 'compression',\n",
       " 824: 'popular',\n",
       " 825: 'groups',\n",
       " 826: 'access',\n",
       " 827: 'variants',\n",
       " 828: 'imagenet',\n",
       " 829: 'advantage',\n",
       " 830: 'unique',\n",
       " 831: 'normal',\n",
       " 832: 'privacy',\n",
       " 833: 'worst',\n",
       " 834: 'notion',\n",
       " 835: 'spaces',\n",
       " 836: 'propagation',\n",
       " 837: 'cell',\n",
       " 838: 'index',\n",
       " 839: 'dimensionality',\n",
       " 840: 'authors',\n",
       " 841: 'yang',\n",
       " 842: 'independently',\n",
       " 843: 'responses',\n",
       " 844: 'analyze',\n",
       " 845: 'runs',\n",
       " 846: 'reported',\n",
       " 847: 'easy',\n",
       " 848: 'department',\n",
       " 849: 'relevant',\n",
       " 850: 'absolute',\n",
       " 851: 'hyperparameters',\n",
       " 852: 'generally',\n",
       " 853: 'bayes',\n",
       " 854: 'diagonal',\n",
       " 855: 'approximations',\n",
       " 856: 'asymptotic',\n",
       " 857: 'interactions',\n",
       " 858: 'extended',\n",
       " 859: 'admm',\n",
       " 860: 'lasso',\n",
       " 861: 'frames',\n",
       " 862: 'equations',\n",
       " 863: 'singular',\n",
       " 864: 'meta',\n",
       " 865: 'functional',\n",
       " 866: 'activity',\n",
       " 867: 'program',\n",
       " 868: 'subspace',\n",
       " 869: 'regions',\n",
       " 870: 'shape',\n",
       " 871: 'empirically',\n",
       " 872: 'represented',\n",
       " 873: 'activations',\n",
       " 874: 'chain',\n",
       " 875: 'ones',\n",
       " 876: 'equilibrium',\n",
       " 877: 'discuss',\n",
       " 878: 'evaluated',\n",
       " 879: 'iterative',\n",
       " 880: 'direct',\n",
       " 881: 'open',\n",
       " 882: 'designed',\n",
       " 883: 'speech',\n",
       " 884: 'euclidean',\n",
       " 885: 'maximizing',\n",
       " 886: 'iclr',\n",
       " 887: 'limit',\n",
       " 888: 'pairwise',\n",
       " 889: 'metrics',\n",
       " 890: 'https',\n",
       " 891: 'plot',\n",
       " 892: 'machines',\n",
       " 893: 'complete',\n",
       " 894: 'hinton',\n",
       " 895: 'combination',\n",
       " 896: 'short',\n",
       " 897: 'challenge',\n",
       " 898: 'extend',\n",
       " 899: 'showed',\n",
       " 900: 'differential',\n",
       " 901: 'return',\n",
       " 902: 'wide',\n",
       " 903: 'factorization',\n",
       " 904: 'explicit',\n",
       " 905: 'event',\n",
       " 906: 'trajectory',\n",
       " 907: 'inner',\n",
       " 908: 'fair',\n",
       " 909: 'follow',\n",
       " 910: 'questions',\n",
       " 911: 'contributions',\n",
       " 912: 'resnet',\n",
       " 913: 'sense',\n",
       " 914: 'mode',\n",
       " 915: 'utility',\n",
       " 916: 'restricted',\n",
       " 917: 'pose',\n",
       " 918: 'minimax',\n",
       " 919: 'fairness',\n",
       " 920: 'scales',\n",
       " 921: 'entire',\n",
       " 922: 'content',\n",
       " 923: 'select',\n",
       " 924: 'comparisons',\n",
       " 925: 'concave',\n",
       " 926: 'baselines',\n",
       " 927: 'arms',\n",
       " 928: 'remark',\n",
       " 929: 'logistic',\n",
       " 930: 'assuming',\n",
       " 931: 'shared',\n",
       " 932: 'frame',\n",
       " 933: 'conclusion',\n",
       " 934: 'past',\n",
       " 935: 'starting',\n",
       " 936: 'predicting',\n",
       " 937: 'changes',\n",
       " 938: 'reduces',\n",
       " 939: 'penalty',\n",
       " 940: 'learner',\n",
       " 941: 'structures',\n",
       " 942: 'technical',\n",
       " 943: 'clear',\n",
       " 944: 'impact',\n",
       " 945: 'simulation',\n",
       " 946: 'retrieval',\n",
       " 947: 'detailed',\n",
       " 948: 'andrew',\n",
       " 949: 'resolution',\n",
       " 950: 'square',\n",
       " 951: 'semantic',\n",
       " 952: 'optimizing',\n",
       " 953: 'item',\n",
       " 954: 'neuron',\n",
       " 955: 'adaptation',\n",
       " 956: 'grant',\n",
       " 957: 'maximize',\n",
       " 958: 'interaction',\n",
       " 959: 'symposium',\n",
       " 960: 'perspective',\n",
       " 961: 'black',\n",
       " 962: 'position',\n",
       " 963: 'developed',\n",
       " 964: 'contribution',\n",
       " 965: 'needed',\n",
       " 966: 'closed',\n",
       " 967: 'trees',\n",
       " 968: 'extension',\n",
       " 969: 'discovery',\n",
       " 970: 'computationally',\n",
       " 971: 'issue',\n",
       " 972: 'shot',\n",
       " 973: 'blocks',\n",
       " 974: 'needs',\n",
       " 975: 'unlike',\n",
       " 976: 'feasible',\n",
       " 977: 'simulated',\n",
       " 978: 'bandits',\n",
       " 979: 'identify',\n",
       " 980: 'combined',\n",
       " 981: 'taken',\n",
       " 982: 'simultaneously',\n",
       " 983: 'vertices',\n",
       " 984: 'environments',\n",
       " 985: 'treatment',\n",
       " 986: 'construction',\n",
       " 987: 'match',\n",
       " 988: 'ensemble',\n",
       " 989: 'correspond',\n",
       " 990: 'adding',\n",
       " 991: 'scaling',\n",
       " 992: 'performing',\n",
       " 993: 'separate',\n",
       " 994: 'false',\n",
       " 995: 'likely',\n",
       " 996: 'accelerated',\n",
       " 997: 'indicates',\n",
       " 998: 'comparing',\n",
       " 999: 'blue',\n",
       " 1000: 'transformations',\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6TmdHynobsp",
    "outputId": "9ef19df5-670d-45bd-b5fc-f50d95783c9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:37:19.456109: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "doc_embed = m.sesh.run(m.mixture.doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kJaNyaEskRC",
    "outputId": "2ec3c927-0e8c-4f24-bc35-ba2851be7da0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:37:20.075586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "topic_embed = m.sesh.run(m.mixture.topic_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ioyv6Ju4vZ-v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-20 00:37:20.518781: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "word_embed = m.sesh.run(m.w_embed.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all unique words in order of index 0-vocab_size\n",
    "vocabulary = []\n",
    "for k,v in idx_to_word.items():\n",
    "    vocabulary.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lengths = np.load(\"clean_data11\" + \"/doc_lengths.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = utils.prepare_topics(doc_embed, topic_embed, word_embed, np.array(vocabulary), doc_lengths=doc_lengths,\n",
    "                              term_frequency=freqs, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "\n * Length of doc_lengths not equal to the number of rows in doc_topic_dists;both should be equal to the number of documents in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/xpt23s1j08vd186gztkz58700000gn/T/ipykernel_19477/1915818940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepared_vis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mvis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mdoc_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_validate\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' * '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: \n * Length of doc_lengths not equal to the number of rows in doc_topic_dists;both should be equal to the number of documents in the data."
     ]
    }
   ],
   "source": [
    "prepared_vis_data = pyLDAvis.prepare(**vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_vis_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t8/xpt23s1j08vd186gztkz58700000gn/T/ipykernel_19477/2638172103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_vis_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_vis_data' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.display(prepared_vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"doc_embed11\", doc_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"word_embed11\", word_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"topic_embed11\", topic_embed)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LDA2Vec",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
